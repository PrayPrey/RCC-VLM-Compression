# Training configuration for RCC compression
optimizer:
  type: "AdamW"
  learning_rate: 1e-4
  weight_decay: 0.01
  betas: [0.9, 0.999]
  eps: 1e-8
  amsgrad: false

scheduler:
  type: "CosineAnnealingLR"
  T_max: 20
  eta_min: 1e-6
  warmup_steps: 1000
  warmup_init_lr: 1e-7

distillation:
  temperature: 4.0
  alpha: 0.3
  distillation_loss: "kl_div"
  feature_matching: true
  attention_transfer: true

mixed_precision:
  enabled: true
  dtype: "float16"
  loss_scale: "dynamic"
  grad_scaler_init: 2048.0

gradient:
  clip_norm: 1.0
  accumulation_steps: 4
  checkpoint_gradients: true

training:
  batch_size: 256
  num_epochs: 20
  eval_frequency: 500
  save_frequency: 1000
  log_frequency: 100
  num_workers: 4
  pin_memory: true